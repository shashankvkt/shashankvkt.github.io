<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shashanka Venkataramanan</title>
  
  <meta name="author" content="Shashanka Venkataramanan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
<link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <link rel   = "stylesheet" href    ="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shashanka Venkataramanan</name>
              </p>
              <p> I am a final year doctoral student with the LinkMedia team at  <a href="https://www.inria.fr/en" target="blank"> INRIA</a>, where I am advised by   <a href="https://avrithis.net/" target="blank">Dr. Yannis Avrithis</a>. My work mainly focuses on developing algorithms to enhance instance and category-level visual representations in the supervised and self-supervised settings. <br><br>

              I recently interned with the video efficiency team at <a href="https://www.qualcomm.com/research/artificial-intelligence/ai-research" target="blank">Qualcomm AI Research</a> in the beautiful city of Amsterdam.
              I graduated with my Masters in C.S from the <a href="https://www.crcv.ucf.edu/" target="blank"> Center for Research in Computer Vision </a> at the University of Central Florida, USA with <a href="https://www.crcv.ucf.edu/person/abhijit-mahalanobis/" target="blank"> Dr. Abhijit Mahalanobis</a>. Prior joining UCF, I spent some time at the <a href="https://www.iisc.ac.in/" target="blank"> Indian Institute of Science</a> as a research assistant with <a href="http://www.ee.iisc.ac.in/people/faculty/soma.biswas/" target="blank"> Dr. Soma Biswas </a> and <a href="https://sites.google.com/site/sivaramprasad443/" target="blank"> Dr. Sivaram Prasad Mudunuri</a>. I feel lucky and am grateful to have worked with them. </p> 

              <p style="text-align:center">
                <a href="mailto:shawshankv16@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/shashank_resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=CbfH47IAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/shawshank_v">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shashank-venkataramanan-1b2b9993/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/shashankvkt">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/shashank_profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/shashank_profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
  
  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Jan 2024: <a href="#" target="_blank">SkipAT and DoRA</a> are accepted to ICLR 2024; DoRA accepted as an <span style="color: red;">Oral</span> <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Sept 2023: <a href="#" target="_blank">MultiMix</a> is accepted to NeurIPS 2023  <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2023: Attending the <a href="https://iplab.dmi.unict.it/icvss2023/Home" target="_blank">ICVSS</a> Summer School in Sicily <br>

                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2023: <a href="https://arxiv.org/pdf/2301.02240.pdf" target="_blank">SkipAT</a>  released on arXiv <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> September 2022: Attending the <a href="https://ivi.fnwi.uva.nl/ellis/event/video-understanding-symposium-2022-8-9-september-2022-amsterdam/" target="_blank"> ELLIS Video Sympsium</a> (invite only) in Amsterdam <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> June 2022: Starting internship with Video Efficiency team at <a href="https://www.qualcomm.com/research/artificial-intelligence/ai-research" target="_blank">Qualcomm AI Research </a> in Amsterdam <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2022: <a href="https://arxiv.org/pdf/2206.14868.pdf" target="_blank">MultiMix</a> released on arXiv <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> February 2022: <a href="https://arxiv.org/pdf/2103.15375.pdf" target="_blank">AlignMixup</a> is accepted to CVPR 2022<br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2022: <a href="https://arxiv.org/pdf/2103.15375.pdf" target="_blank">Metrix</a> is accepted to ICLR 2022<br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> December 2021: Teaching Deep Metric learning course at MathSTIC <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> September 2021: Attending the <a href="https://ellis.eu/events/ellis-doctoral-symposium" target="_blank">ELLIS doctoral symposium</a> in Tubingen <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> December 2020: Started my PhD at INRIA<br>
                
              </p>
            </td>
          </tr>
        </tbody></table> -->

    <!-- </body> -->



<div style="width:100%; overflow-y: auto; max-height: 135px;">
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>News</heading>
          <p>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2024: <a href="#" target="_blank">DoRA</a> received an <span style="color: red;">Outstanding paper honorable mention</span> at ICLR 2024 <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> April 2024: Hosting the 1st edition of our tutorial <a href="https://shashankvkt.github.io/eccv2024-SSLBIG-tutorial.github.io/" target="_blank">Self-Supervised Learning Beyond Images</a> at <a href="https://eccv2024.ecva.net/" target="_blank">ECCV 2024</a> in Milan!!  <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> April 2024: Invited to give a talk at Meta AI (FAIR) in Paris  <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Jan 2024: Invited to give a talk at IBM Research, Zurich (online) <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Jan 2024: <a href="#" target="_blank">SkipAT and DoRA</a> are accepted to ICLR 2024; DoRA accepted as an <span style="color: red;">Oral</span> <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Sept 2023: <a href="#" target="_blank">MultiMix</a> is accepted to NeurIPS 2023  <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2023: Attending the <a href="https://iplab.dmi.unict.it/icvss2023/Home" target="_blank">ICVSS</a> Summer School in Sicily <br>

            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2023: <a href="https://arxiv.org/pdf/2301.02240.pdf" target="_blank">SkipAT</a>  released on arXiv <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> September 2022: Attending the <a href="https://ivi.fnwi.uva.nl/ellis/event/video-understanding-symposium-2022-8-9-september-2022-amsterdam/" target="_blank"> ELLIS Video Sympsium</a> (invite only) in Amsterdam <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> June 2022: Starting internship with Video Efficiency team at <a href="https://www.qualcomm.com/research/artificial-intelligence/ai-research" target="_blank">Qualcomm AI Research </a> in Amsterdam <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2022: <a href="https://arxiv.org/pdf/2206.14868.pdf" target="_blank">MultiMix</a> released on arXiv <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> February 2022: <a href="https://arxiv.org/pdf/2103.15375.pdf" target="_blank">AlignMixup</a> is accepted to CVPR 2022<br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2022: <a href="https://arxiv.org/pdf/2103.15375.pdf" target="_blank">Metrix</a> is accepted to ICLR 2022<br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> December 2021: Teaching Deep Metric learning course at MathSTIC <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> September 2021: Attending the <a href="https://ellis.eu/events/ellis-doctoral-symposium" target="_blank">ELLIS doctoral symposium</a> in Tubingen <br>
            &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> December 2020: Started my PhD at INRIA<br>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
</div>



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <tr>
             <td style="padding:20px;width:100%;vertical-align:middle"> 
               <heading>Publications</heading>
            </td>
        </tr> 
    </tbody></table>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  
   <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/dora_2023.png" alt="DoRA-2023" height="150" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/pdf/2310.08584.pdf" id="MCG_journal">
                <papertitle>Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video</papertitle>
              </a>
              <br>
              <strong>Shashanka Venkataramanan</strong>, <a href="https://nayeemrizve.github.io/">Mamshad Nayeem Rizve</a>, <a href="https://scholar.google.co.uk/citations?user=IUZ-7_cAAAAJ&hl=en/">Jo√£o Carreira</a>, <a href="https://yukimasano.github.io/">Yuki M. Asano*</a>, <a href="https://avrithis.net/">Yannis Avrithis*</a> 
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2024 <br><span style="color: red;">Outstanding paper honorable mention</span>
              <br>
              <a href="http://arxiv.org/pdf/2310.08584.pdf">paper</a>&nbsp;/&nbsp;
              <a href="https://openreview.net/forum?id=Yen1lGns2o">OpenReview</a>&nbsp;/&nbsp;
              <a href="https://shashankvkt.github.io/dora">project page</a>&nbsp;/&nbsp;
              <a href="https://huggingface.co/datasets/shawshankvkt/Walking_Tours">HF dataset</a>&nbsp;/&nbsp;
              <a href="https://github.com/shashankvkt/DoRA_ICLR24">code</a>&nbsp;/&nbsp;
              <a href="data/dora_2023.bib">bibtex</a> 
            </td>
          </tr>


  <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/skipat_2023.png" alt="skipAT-2023" height="60" width="180" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2301.02240.pdf" id="MCG_journal">
                <papertitle>Skip-Attention: Improving Vision Transformers by Paying Less Attention</papertitle>
              </a>
              <br>
              <strong>Shashanka Venkataramanan</strong>, <a href="https://scholar.google.be/citations?user=h1IvkAsAAAAJ&hl=en">Amir Ghodrati</a>, <a href="https://yukimasano.github.io/">Yuki M. Asano</a>, <a href="https://www.porikli.com/">Fatih Porikli</a>, <a href="https://habibian.github.io/">Amirhossein Habibian</a>
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2301.02240.pdf">paper</a>&nbsp;/&nbsp;
              <a href="https://github.com/Qualcomm-AI-research/skip-attention">Code</a>&nbsp;/&nbsp;
              <a href="data/skipat_2023.bib">bibtex</a> 
              
      
            </td>
          </tr>
  <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/multimix_2022.png" alt="MultiMix-2023" height="80" width="150" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2311.05538" id="MCG_journal">
                <papertitle>Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond Examples</papertitle>
              </a>
              <br>
              <strong>Shashanka Venkataramanan</strong>, <a href="http://people.irisa.fr/Ewa.Kijak/">Ewa Kijak</a>, <a href="http://people.rennes.inria.fr/Laurent.Amsaleg/">Laurent Amsaleg</a>, <a href="https://avrithis.net/">Yannis Avrithis</a>
              <br>
              <em>Neural Information Processing Systems (NeurIPS)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2311.05538">arxiv</a>&nbsp;/&nbsp;
              <a href="https://inria.hal.science/hal-04214672/file/MultiMix_NeurIPS23.pdf">HAL</a>&nbsp;/&nbsp;
              <a href="data/multimix_2022.bib">bibtex</a>&nbsp;/&nbsp;
              <a href="Coming soon#">code</a>&nbsp;/&nbsp;
              <a href="Coming soon#">video</a>&nbsp;/&nbsp;
              <a href="Coming soon#">slides</a>&nbsp;/&nbsp;
              <a href="Coming soon#">poster</a>
              
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/alignmixup_cvpr2022.jpg" alt="alignmix-cvpr2022" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2103.15375.pdf" id="MCG_journal">
                <papertitle> AlignMixup: Improving Representations By Interpolating Aligned Features</papertitle>
              </a>
              <br>
              <strong>Shashanka Venkataramanan</strong>, <a href="http://people.irisa.fr/Ewa.Kijak/">Ewa Kijak</a>, <a href="http://people.rennes.inria.fr/Laurent.Amsaleg/">Laurent Amsaleg</a>, <a href="https://avrithis.net/">Yannis Avrithis</a>
              <br>
              <em>IEEE/CVF Proceedings on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2103.15375.pdf">arxiv</a>&nbsp;/&nbsp;
              <a href="https://inria.hal.science/hal-03620779/file/AlignMix_CVPR22_cameraReady.pdf">HAL</a>&nbsp;/&nbsp;
              <a href="data/alignmixup_cvpr2022.bib">bibtex</a>&nbsp;/&nbsp;
              <a href="https://github.com/shashankvkt/AlignMixup_CVPR22">code</a>
        <p></p>
              
        
            </td>
          </tr>
    
    
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/metrix_iclr2022.png" alt="metrix-iclr2022" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2106.04990.pdf" id="MCG_journal">
                <papertitle>It Takes Two to Tango: Mixup for Deep Metric Learning</papertitle>
              </a>
              <br>
              <strong>Shashanka Venkataramanan</strong>, <a href="http://users.ntua.gr/psomasbill/">Bill Psomas</a>, <a href="http://people.irisa.fr/Ewa.Kijak/">Ewa Kijak</a>, <a href="http://people.rennes.inria.fr/Laurent.Amsaleg/">Laurent Amsaleg</a>, <a href="http://users.ntua.gr/karank/">Konstantinos Karantzalos</a>, <a href="https://avrithis.net/">Yannis Avrithis</a>
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2106.04990.pdf">arxiv</a>&nbsp;/&nbsp;
              <a href="data/metrix_iclr2022.bib">bibtex</a>&nbsp;/&nbsp;
              <a href="https://github.com/billpsomas/Metrix_ICLR22">code</a>&nbsp;/&nbsp;
              <a href="https://iclr.cc/virtual/2022/poster/6337">video</a>&nbsp;/&nbsp;
              <a href="https://github.com/billpsomas/Metrix_ICLR22/blob/master/.github/slides.pdf">slides</a>&nbsp;/&nbsp;
              <a href="https://github.com/billpsomas/Metrix_ICLR22/blob/master/.github/poster.pdf">poster</a>
              
            </td>
          </tr>
    
    
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/cavga_eccv2020.png" alt="cavga-eccv2020" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.08616" id="MCG_journal">
                <papertitle> Attention Guided Anomaly Localization in Images</papertitle>
              </a>
              <br>
               <strong>  Shashanka Venkataramanan</strong>, <a href="https://www.merl.com/people/kpeng">Kuan-Chuan Peng</a>, <a href="http://rajatvikramsingh.github.io/">Rajat Vikram Singh</a>, <a href="https://www.crcv.ucf.edu/person/abhijit-mahalanobis/">Abhijit Mahalanobis </a>
              <br>
              <em>In European Conference on Computer Vision (ECCV)</em>, 2020
              <br>
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620477.pdf">paper</a>&nbsp;/&nbsp;
              <a href="data/cavga_eccv2020.bib">bibtex</a>&nbsp;/&nbsp;
              <a href="https://arxiv.org/abs/1911.08616">arxiv</a>&nbsp;/&nbsp; 
              <a href="https://youtu.be/b-EQr-fGPWo"> teaser video</a>&nbsp;/&nbsp;
              <a href="https://www.youtube.com/watch?v=n0t4gthI0fM"> main video</a> 
             
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/tclr_icip2020.jpg" alt="tclr-icip2020" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2101.07974" id="MCG_journal">
                <papertitle>Target Detection in Cluttered Environments using Infra-red Images</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/bwmcintosh/">Bruce McIntosh</a>, <strong>  Shashanka Venkataramanan</strong>,  <a href="https://www.crcv.ucf.edu/person/abhijit-mahalanobis/">Abhijit Mahalanobis </a>
              <br>
              <em>IEEE International Conference on Image Processing (ICIP)</em>, 2020
              <br>
              <a href="https://www.crcv.ucf.edu/wp-content/uploads/2020/07/icip2020_photoready.pdf">arxiv</a>&nbsp;/&nbsp;
              <a href="data/tclr_icip2020.bib">bibtex</a> 
              
              
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/dalign_tifs2019.jpg" alt="dalign-tifs2019" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2103.01315" id="MCG_journal">
                <papertitle>Dictionary alignment with re-ranking for low-resolution NIR-VIS face recognition</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/site/sivaramprasad443/">Sivaram Prasad Mudunuri*</a>, <strong>  Shashanka Venkataramanan*</strong>,  <a href="http://www.ee.iisc.ac.in/people/faculty/soma.biswas/">Soma Biswas </a>
              <br>
              <em>IEEE Transactions on Information Forensics and Security</em>, 2019
              <br>
              <a href="http://www.ee.iisc.ac.in/people/faculty/soma.biswas/Papers/DAlign_tifs2019.pdf">paper</a>&nbsp;/&nbsp;
              <a href="data/dalign_tifs2019.bib">bibtex</a>&nbsp;/&nbsp;
              <a href="https://github.com/shashankvkt/dualranking_TIFS_2018">code</a> 
              
            </td>
          </tr>

         

        </tbody></table>





       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <tr>
             <td style="padding:20px;width:100%;vertical-align:middle"> 
               <heading>Workshops and Tutorials</heading>
            </td>
        </tr> 
    </tbody></table>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/eccv_logo.png" alt="skipAT-2023" height="100" width="180" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://shashankvkt.github.io/eccv2024-SSLBIG-tutorial.github.io/" id="MCG_journal">
                <papertitle>Time is precious: Self-Supervised Learning Beyond Images</papertitle>
              </a>
              <br>
              <strong>Shashanka Venkataramanan</strong>, <a href="https://scholar.google.com/citations?user=kpT3gcsAAAAJ&hl=en">Mohammadreza Salehi</a>, <a href="https://yukimasano.github.io/">Yuki M. Asano</a>
              <br>
              <em>ECCV</em>, 2024
             
              
              
      
            </td>
          </tr>
  
          

         

        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <tr>
             <td style="padding:20px;width:100%;vertical-align:middle"> 
               <heading>Academic Services</heading>
            </td>
        </tr> 
    </tbody></table>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <p>
            <li><span> [2023] Reviewer for <a href="https://cvpr2023.thecvf.com/" target="_blank">CVPR</a>
            <li><span> [2022] Reviewer for <a href="https://iclr.cc/" target="_blank">ICLR</a>, <a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR</a>, <a href="https://eccv2022.ecva.net/" target="_blank">ECCV</a>, <a href="https://nips.cc/Conferences/2022/" target="_blank">NeurIPS</a> </span></li>
            <li><span> [2021] Reviewer for <a href="http://iccv2021.thecvf.com/home" target="_blank">ICCV</a>, <a href="https://2021.acmmm.org/" target="_blank">ACM Multimedia</a>, <a href="https://www.acmmmasia.org/" target="_blank">ACM Multimedia Asia</a> </span></li>

              </p>
            </td>
          </tr>

  </tbody></table>      
        

  </table>
</body>

</html>
